{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "private_outputs": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMaamktE/ciPIYPKxLZ8Ms3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jermwatt/morphi_lab/blob/collab_demos/scratch_notebooks/3_image_demo_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.  Setup"
      ],
      "metadata": {
        "id": "kVbKjgHovhAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Machine check"
      ],
      "metadata": {
        "id": "NqvrZr526EDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "XZEkR12-eG-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Installs"
      ],
      "metadata": {
        "id": "YGc-wRzC6ArW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iHfZS44dDgY"
      },
      "outputs": [],
      "source": [
        "# install reqiured libraries \n",
        "!pip install \"ultralytics==8.0.111\" \"transformers==4.29.2\" \"timm==0.9.2\" \"diffusers==0.16.1\" \"safetensors==0.3.1\" \"accelerate==0.19.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2.  diffusion model import and download"
      ],
      "metadata": {
        "id": "CVynTcEA6Q5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionInpaintPipeline\n",
        "\n",
        "# define diffusion pipeline - first call will download model\n",
        "device = \"cuda\"\n",
        "diffusion_pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
        "     torch_dtype=torch.float16).to(device)\n",
        "\n",
        "# turn off progress bars when processing input image\n",
        "# diffusion_pipe.set_progress_bar_config(leave=False)\n",
        "# diffusion_pipe.set_progress_bar_config(disable=True)"
      ],
      "metadata": {
        "id": "Kd8hBRFK59Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Choose YOLO model, download"
      ],
      "metadata": {
        "id": "PS3bASRI6xqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# curl desired model\n",
        "available_models = {\n",
        "    'large' :{'client_name':'YOLOv8l-seg.pt', 'server_name':'yolov8l-seg.pt'},\n",
        "    'medium':{'client_name':'YOLOv8m-seg.pt', 'server_name':'yolov8m-seg.pt'},\n",
        "    'small' :{'client_name':'YOLOv8s-seg.pt', 'server_name':'yolov8s-seg.pt'},\n",
        "    'nano'  :{'client_name':'YOLOv8n-seg.pt', 'server_name':'yolov8n-seg.pt'}\n",
        "}"
      ],
      "metadata": {
        "id": "RzOdrHyA59Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# !curl -sSL -o /content/YOLOv8l-seg.pt https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-seg.pt\n",
        "\n",
        "def pull_yolo_model(model_selection):\n",
        "  # create server url\n",
        "  server_url = \"https://github.com/ultralytics/assets/releases/download/v0.0.0/\" + model_selection[\"server_name\"]\n",
        "\n",
        "  # create local save location\n",
        "  local_save = \"/content/\" + model_selection[\"client_name\"]\n",
        "\n",
        "  # pull yolo model to this macine\n",
        "  response = requests.get(server_url, stream=True)\n",
        "  response.raise_for_status()\n",
        "  with open(local_save, \"wb\") as file:\n",
        "      for chunk in response.iter_content(chunk_size=8192):\n",
        "          if chunk:\n",
        "              file.write(chunk)\n",
        "  \n",
        "  # return local_save location to pass onto segmenter\n",
        "  return local_save"
      ],
      "metadata": {
        "id": "vFtbQdpJ59Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = available_models['large']\n",
        "yolo_model_location = pull_yolo_model(model)"
      ],
      "metadata": {
        "id": "roW_LCYM8Yg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4. download image"
      ],
      "metadata": {
        "id": "N6Do_-S7Ce7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pull image\n",
        "!curl -sSL -o /content/test_img.png https://github.com/jermwatt/morphi_lab/blob/collab_demos/test_data/test_input/test_img.png?raw=true \n"
      ],
      "metadata": {
        "id": "hKZbObGTCfTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -sSL -o /content/test_donut.png https://www.shutterstock.com/image-photo/surprised-young-man-holding-donut-260nw-586330142.jpg"
      ],
      "metadata": {
        "id": "nkmsPPIUuGQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4.  segmentation"
      ],
      "metadata": {
        "id": "I4iUFXL99CQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_lookup_dict = {\n",
        "  \"person\": 0,\n",
        "  \"bicycle\": 1,\n",
        "  \"car\": 2,\n",
        "  \"motorcycle\": 3,\n",
        "  \"airplane\": 4,\n",
        "  \"bus\": 5,\n",
        "  \"train\": 6,\n",
        "  \"truck\": 7,\n",
        "  \"boat\": 8,\n",
        "  \"traffic light\": 9,\n",
        "  \"fire hydrant\": 10,\n",
        "  \"stop sign\": 11,\n",
        "  \"parking meter\": 12,\n",
        "  \"bench\": 13,\n",
        "  \"bird\": 14,\n",
        "  \"cat\": 15,\n",
        "  \"dog\": 16,\n",
        "  \"horse\": 17,\n",
        "  \"sheep\": 18,\n",
        "  \"cow\": 19,\n",
        "  \"elephant\": 20,\n",
        "  \"bear\": 21,\n",
        "  \"zebra\": 22,\n",
        "  \"giraffe\": 23,\n",
        "  \"backpack\": 24,\n",
        "  \"umbrella\": 25,\n",
        "  \"handbag\": 26,\n",
        "  \"tie\": 27,\n",
        "  \"suitcase\": 28,\n",
        "  \"frisbee\": 29,\n",
        "  \"skis\": 30,\n",
        "  \"snowboard\": 31,\n",
        "  \"sports ball\": 32,\n",
        "  \"kite\": 33,\n",
        "  \"baseball bat\": 34,\n",
        "  \"baseball glove\": 35,\n",
        "  \"skateboard\": 36,\n",
        "  \"surfboard\": 37,\n",
        "  \"tennis racket\": 38,\n",
        "  \"bottle\": 39,\n",
        "  \"wine glass\": 40,\n",
        "  \"cup\": 41,\n",
        "  \"fork\": 42,\n",
        "  \"knife\": 43,\n",
        "  \"spoon\": 44,\n",
        "  \"bowl\": 45,\n",
        "  \"banana\": 46,\n",
        "  \"apple\": 47,\n",
        "  \"sandwich\": 48,\n",
        "  \"orange\": 49,\n",
        "  \"broccoli\": 50,\n",
        "  \"carrot\": 51,\n",
        "  \"hot dog\": 52,\n",
        "  \"pizza\": 53,\n",
        "  \"donut\": 54,\n",
        "  \"cake\": 55,\n",
        "  \"chair\": 56,\n",
        "  \"couch\": 57,\n",
        "  \"potted plant\": 58,\n",
        "  \"bed\": 59,\n",
        "  \"dining table\": 60,\n",
        "  \"toilet\": 61,\n",
        "  \"tv\": 62,\n",
        "  \"laptop\": 63,\n",
        "  \"mouse\": 64,\n",
        "  \"remote\": 65,\n",
        "  \"keyboard\": 66,\n",
        "  \"cell phone\": 67,\n",
        "  \"microwave\": 68,\n",
        "  \"oven\": 69,\n",
        "  \"toaster\": 70,\n",
        "  \"sink\": 71,\n",
        "  \"refrigerator\": 72,\n",
        "  \"book\": 73,\n",
        "  \"clock\": 74,\n",
        "  \"vase\": 75,\n",
        "  \"scissors\": 76,\n",
        "  \"teddy bear\": 77,\n",
        "  \"hair drier\": 78,\n",
        "  \"toothbrush\": 79\n",
        "}"
      ],
      "metadata": {
        "id": "Vtu42KM8_Df1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import torchvision\n",
        "from torchvision.io import read_image\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "parent_dir = os.getcwd()\n",
        "\n",
        "# define transforms for processing tensors\n",
        "resizer = transforms.Resize((448, 640),antialias=True)\n",
        "clipper = transforms.Lambda(lambda x: x[:3])\n",
        "\n",
        "\n",
        "class Segmenter:\n",
        "    def __init__(self, \n",
        "                 yolo_model_location,\n",
        "                 labels=['bottle','cup'],\n",
        "                 conf=0.25,\n",
        "                 max_det=1):\n",
        "        self.conf = conf\n",
        "        self.model = YOLO(yolo_model_location)\n",
        "        try:\n",
        "          self.model.to('cuda')\n",
        "        except:\n",
        "          pass\n",
        "        self.labels_text = labels\n",
        "        self.labels_ints = [label_lookup_dict[v] for v in labels]\n",
        "        self.max_det = max_det\n",
        "\n",
        "        self.img = None\n",
        "        self.img_height = None\n",
        "        self.img_width = None\n",
        "        self.xmin = None\n",
        "        self.ymin = None\n",
        "        self.xmax = None\n",
        "        self.ymax = None\n",
        "        self.seg = None\n",
        "        self.segmentation_result = None\n",
        "        self.detection_window_path = parent_dir + '/temp/temp.png'\n",
        "\n",
        "    def reset(self):\n",
        "        self.img = None\n",
        "        self.xmin = None\n",
        "        self.ymin = None\n",
        "        self.xmax = None\n",
        "        self.ymax = None\n",
        "        self.seg = None\n",
        "        self.width = None\n",
        "        self.height = None\n",
        "        self.segmentation_result = None\n",
        "\n",
        "    def read_img_path(self, img_path):\n",
        "        self.reset()\n",
        "        self.img = clipper(resizer(read_image(img_path))).unsqueeze(0)\n",
        "        shapes = self.img.shape\n",
        "        h = shapes[3]\n",
        "        w = shapes[2]\n",
        "        self.height = h\n",
        "        self.width = w\n",
        "\n",
        "    def read_img(self, img):\n",
        "        self.reset()\n",
        "        self.img = img\n",
        "        h, w, _ = self.img.shape\n",
        "        self.height = h\n",
        "        self.width = w\n",
        "\n",
        "    def segment(self):\n",
        "        self.segmentation_result = self.model.predict(source=self.img,\n",
        "                                                      classes=self.labels_ints,\n",
        "                                                      conf=self.conf,\n",
        "                                                      show_labels=False,\n",
        "                                                      boxes=False,\n",
        "                                                      verbose=False,\n",
        "                                                      half=True,\n",
        "                                                      max_det=self.max_det)\n",
        "\n",
        "        # class names\n",
        "        self.class_names = self.model.names\n",
        "\n",
        "        # random colors for plotting\n",
        "        # self.colors = [[random.randint(0, 255) for _ in range(3)] for _ in self.class_names]\n",
        "        self.colors = [[100,0,100] for _ in self.class_names]\n",
        "\n",
        "        # extract segmentation result\n",
        "        batch, channels, h, w = self.img.shape\n",
        "        boxes = self.segmentation_result[0].boxes\n",
        "        masks = self.segmentation_result[0].masks\n",
        "\n",
        "        if masks is not None:\n",
        "            masks = masks.data.cpu()\n",
        "            for seg, box in zip(masks.data.cpu().numpy(), boxes):\n",
        "                seg = cv2.resize(seg, (w, h)).astype(np.uint8)\n",
        "\n",
        "                self.xmin = int(box.data[0][0])\n",
        "                self.ymin = int(box.data[0][1])\n",
        "                self.xmax = int(box.data[0][2])\n",
        "                self.ymax = int(box.data[0][3])\n",
        "                self.seg = seg\n",
        "\n",
        "                self.detection_window = self.img[self.ymin:self.ymax,\n",
        "                                                 self.xmin:self.xmax]\n",
        "\n",
        "                break\n",
        "\n",
        "    def save_segment(self):\n",
        "        cv2.imwrite(self.detection_window_path, self.detection_window)\n",
        "\n",
        "    @staticmethod\n",
        "    def overlay(image, mask, color, alpha, resize=None):\n",
        "        colored_mask = np.stack((mask,)*3, axis=-1)\n",
        "        masked = np.ma.MaskedArray(image, mask=colored_mask, fill_value=color)\n",
        "        image_overlay = masked.filled()\n",
        "\n",
        "        if resize is not None:\n",
        "            image = cv2.resize(image.transpose(1, 2, 0), resize)\n",
        "            image_overlay = cv2.resize(image_overlay.transpose(1, 2, 0), resize)\n",
        "\n",
        "        image_combined = cv2.addWeighted(image, 1 - alpha, image_overlay, alpha, 0)\n",
        "\n",
        "        return image_combined\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_one_box(x, img, color=None, label=None, line_thickness=3):\n",
        "        # Plots one bounding box on image img\n",
        "        tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
        "        color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "        c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "        cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "        if label:\n",
        "            tf = max(tl - 1, 1)  # font thickness\n",
        "            t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "            c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "            cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
        "            cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "\n",
        "    def project_segmentations(self, show_overlay=True, show_boxes=False, show_result=False):\n",
        "        # bring img back to cpu \n",
        "        self.img = self.img.cpu().numpy()\n",
        "        self.img = np.squeeze(self.img).transpose((1, 2, 0))\n",
        "\n",
        "        # unpack segmentation results\n",
        "        boxes = self.segmentation_result[0].boxes\n",
        "        masks = self.segmentation_result[0].masks\n",
        "\n",
        "        # loop over masks and plot\n",
        "        if masks is not None:\n",
        "            masks = masks.data.cpu()\n",
        "            for seg, box in zip(masks.data.cpu().numpy(), boxes):   \n",
        "                if show_overlay:\n",
        "                    self.img = self.overlay(self.img, seg, self.colors[int(box.cls)], 0.4)\n",
        "\n",
        "                xmin = int(box.data[0][0])\n",
        "                ymin = int(box.data[0][1])\n",
        "                xmax = int(box.data[0][2])\n",
        "                ymax = int(box.data[0][3])\n",
        "\n",
        "                if show_boxes:\n",
        "                    self.plot_one_box([xmin, ymin, xmax, ymax],\n",
        "                                      self.img,\n",
        "                                      self.colors[int(box.cls)],\n",
        "                                      f'{self.class_names[int(box.cls)]} {float(box.conf):.3}')\n",
        "\n",
        "    def show_result(self):\n",
        "        plt.imshow(self.img)\n",
        "        plt.axis('off')  # optional: disable the axis\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "WNpazu-C8YkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SYh9EmVqccT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_image(img_path,\n",
        "                  labels=['bottle','cup'],\n",
        "                  conf=0.05,\n",
        "                  max_det=1):\n",
        "  \n",
        "    # create instance of Segmenter\n",
        "    seg = Segmenter(yolo_model_location,\n",
        "                    labels=labels,\n",
        "                    conf=conf,\n",
        "                    max_det=max_det)\n",
        "    \n",
        "    # run segment\n",
        "    seg.read_img_path(img_path)\n",
        "    seg.segment()\n",
        "    seg.project_segmentations()\n",
        "\n",
        "    # unpack image and mask from segmenter\n",
        "    img = seg.img\n",
        "\n",
        "    # extract mask - bring back to cpu\n",
        "    mask = seg.segmentation_result[0].masks.data[0].cpu().numpy()\n",
        "    mask = (mask * 255).astype(np.uint8)\n",
        "    mask = np.stack((mask,) * 3, axis=2)\n",
        "\n",
        "    return img, mask, seg"
      ],
      "metadata": {
        "id": "BioLjeGnCCnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/test_donut.png\"\n",
        "labels = ['bottle','cup']\n",
        "labels = ['donut']\n",
        "conf = 0.05\n",
        "max_det = 1\n",
        "img, mask, seg = segment_image(img_path,\n",
        "                               labels=labels,\n",
        "                               conf=conf,\n",
        "                               max_det=max_det)"
      ],
      "metadata": {
        "id": "ucehWEPVI3u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seg.show_result()"
      ],
      "metadata": {
        "id": "E2Dt93-tCCqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. diffuse object"
      ],
      "metadata": {
        "id": "De_NWYAJENBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# diffuse image / mask\n",
        "def diffuse(img,\n",
        "            mask,\n",
        "            prompt=\"realistic coca cola can, high resolution, high quality, logo visible, red and white colors, aluminum\",\n",
        "            negative_prompt='fingers, dented can, crushed can, bottle, plastic, low quality, low resolution',\n",
        "            seed=None\n",
        "            ):\n",
        "\n",
        "    # prep img for diffusion\n",
        "    img_pil = Image.fromarray(img).convert('RGB').resize((512, 512))\n",
        "\n",
        "    # prep mask for diffusion\n",
        "    mask_pil = Image.fromarray(mask).convert('RGB').resize((512, 512))\n",
        "\n",
        "    # difuse mask\n",
        "    if seed is not None:\n",
        "        if isinstance(seed,int):\n",
        "            torch.manual_seed(seed)\n",
        "    diffused_img = diffusion_pipe(\n",
        "                                  prompt=prompt,\n",
        "                                  negative_prompt=negative_prompt,\n",
        "                                  image=img_pil,\n",
        "                                  mask_image=mask_pil,\n",
        "                                  num_inference_steps=100,\n",
        "                                  output_type='np.array').images[0]\n",
        "\n",
        "    # resize to match input img / mask \n",
        "    diffused_img = cv2.resize(diffused_img, (img.shape[1], img.shape[0]))\n",
        "    return diffused_img"
      ],
      "metadata": {
        "id": "78C-TzyiEj--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diffused_img = diffuse(img,\n",
        "                       mask,\n",
        "                       seed=3433)"
      ],
      "metadata": {
        "id": "bquTuw7DLCAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6. Prep all imgs for showing "
      ],
      "metadata": {
        "id": "yadoN445NZus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_diffuse_results(segmented_img,\n",
        "                         mask,\n",
        "                         diffused_img):\n",
        "  # Create a figure with three subplots\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
        "\n",
        "  # Display the first image\n",
        "  # axes[0].imshow(cv2.cvtColor(segmented_img, cv2.COLOR_BGR2RGB))\n",
        "  axes[0].imshow(segmented_img)\n",
        "\n",
        "  axes[0].axis('off')\n",
        "  axes[0].set_title('segmented image')\n",
        "\n",
        "  # Display the second image\n",
        "  axes[1].imshow(mask)\n",
        "  axes[1].axis('off')\n",
        "  axes[1].set_title('object segmentations')\n",
        "\n",
        "  # Display the third image\n",
        "  axes[2].imshow(diffused_img)\n",
        "  axes[2].axis('off')\n",
        "  axes[2].set_title('diffused image')\n",
        "\n",
        "  # Adjust the layout\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the figure\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "teyWz-SQZm25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_diffuse_results(img,\n",
        "                     mask,\n",
        "                     diffused_img)"
      ],
      "metadata": {
        "id": "M3mSiCyELwFk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}